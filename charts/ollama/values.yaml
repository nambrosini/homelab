open-webui:
  ollama:
    enabled: true
    models:
      - llama3.1
      - mistral
    resources:
      requests:
        cpu: "1000m"
        memory: "2Gi"
      limits:
        cpu: "2000m"
        memory: "8Gi"

  clusterDomain: cluster.local
  resources:
    requests:
      cpu: "500m"
      memory: "500Mi"
    limits:
      cpu: "1000m"
      memory: "1Gi"
